{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Raw Data by using API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to call the OpenChargeMap API\n",
    "import requests\n",
    "# to save the fetched data\n",
    "import json\n",
    "# to control request rate and calculate runtime\n",
    "import time\n",
    "# to generate grid of lat/lon coordinates\n",
    "import numpy as np\n",
    "# Optional: silence warnings\n",
    "import urllib3\n",
    "\n",
    "\n",
    "\n",
    "# === CONFIG ===\n",
    "API_KEY = \"your_api_key_here\"  # Replace with your Open Charge Map API key\n",
    "BASE_URL = \"https://api.openchargemap.io/v3/poi/\"\n",
    "OUTPUT_FILE = \"../data/ocm_germany_full.json\"\n",
    "SLEEP_BETWEEN_REQUESTS = 1\n",
    "MAX_RESULTS = 1000\n",
    "DISTANCE_KM = 50\n",
    "\n",
    "# === DEV MODE ===\n",
    "DEV_MODE = False\n",
    "DEV_LIMIT = 5  # Max number of stations to fetch in dev mode\n",
    "\n",
    "# === Generate Grid Over Germany ===\n",
    "lat_range = np.arange(47.0, 55.5, 1.0)\n",
    "lon_range = np.arange(5.5, 15.5, 1.0)\n",
    "regions = [(round(lat, 2), round(lon, 2)) for lat in lat_range for lon in lon_range]\n",
    "\n",
    "fetched_ids = set()\n",
    "all_data = []\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"üöÄ Fetching Open Charge Map data for Germany using {len(regions)} tiles...\\n\")\n",
    "\n",
    "for i, (lat, lon) in enumerate(regions, start=1):\n",
    "    print(f\"\\nüìç Region {i}/{len(regions)}: lat={lat}, lon={lon}\")\n",
    "    offset = 0\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"output\": \"json\",\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"distance\": DISTANCE_KM,\n",
    "            \"distanceunit\": \"KM\",\n",
    "            \"maxresults\": MAX_RESULTS,\n",
    "            \"offset\": offset,\n",
    "            \"sort\": \"ID\",\n",
    "            \"compact\": \"false\",\n",
    "            \"key\": API_KEY\n",
    "        }\n",
    "\n",
    "        response = requests.get(BASE_URL, params=params, verify=False)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(\"‚ùå API error:\", response.status_code, response.text)\n",
    "            break\n",
    "\n",
    "        batch = response.json()\n",
    "        if not batch:\n",
    "            print(\"‚úÖ No more results in this region.\")\n",
    "            break\n",
    "\n",
    "        new_records = 0\n",
    "        for entry in batch:\n",
    "            station_id = entry.get(\"ID\")\n",
    "            if station_id and station_id not in fetched_ids:\n",
    "                fetched_ids.add(station_id)\n",
    "                all_data.append(entry)\n",
    "                new_records += 1\n",
    "\n",
    "                if DEV_MODE and len(all_data) >= DEV_LIMIT:\n",
    "                    print(f\"üß™ DEV Mode: Reached {DEV_LIMIT} records.\")\n",
    "                    break  # Exit entry loop\n",
    "\n",
    "        print(f\"‚ûï Added {new_records} new records from offset {offset}\")\n",
    "\n",
    "        if new_records == 0 or (DEV_MODE and len(all_data) >= DEV_LIMIT):\n",
    "            print(\"‚õî Stopping pagination for this region.\")\n",
    "            break  # Exit pagination loop\n",
    "\n",
    "        offset += MAX_RESULTS\n",
    "        time.sleep(SLEEP_BETWEEN_REQUESTS)\n",
    "\n",
    "    if DEV_MODE and len(all_data) >= DEV_LIMIT:\n",
    "        print(\"‚úÖ DEV Mode: Stopping outer loop early.\")\n",
    "        break  # Exit region loop\n",
    "\n",
    "# === Save Results ===\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "runtime = round(time.time() - start_time, 2)\n",
    "print(f\"\\nüéâ Finished! Total unique records: {len(all_data)}\")\n",
    "print(f\"üìÅ Data saved to: {OUTPUT_FILE}\")\n",
    "print(f\"‚è±Ô∏è Runtime: {runtime} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Data in csv format for SQL-Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# üîÅ Load your JSON data (replace with your actual file)\n",
    "with open(\"../data/ocm_germany_full.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# üß± Setup data containers\n",
    "stations, connections = [], []\n",
    "operators, usage_types, status_types = {}, {}, {}\n",
    "connection_types, charging_levels, current_types = {}, {}, {}\n",
    "data_providers, countries = {}, {}\n",
    "\n",
    "for item in data:\n",
    "    station_id = item[\"ID\"]\n",
    "    address = item.get(\"AddressInfo\", {})\n",
    "    country = address.get(\"Country\", {})\n",
    "\n",
    "    stations.append({\n",
    "        \"station_id\": station_id,\n",
    "        \"title\": address.get(\"Title\"),\n",
    "        \"city\": address.get(\"Town\"),\n",
    "        \"postcode\": address.get(\"Postcode\"),\n",
    "        \"country_id\": country.get(\"ID\"),\n",
    "        \"latitude\": address.get(\"Latitude\"),\n",
    "        \"longitude\": address.get(\"Longitude\"),\n",
    "        \"operator_id\": item.get(\"OperatorID\"),\n",
    "        \"usage_type_id\": item.get(\"UsageTypeID\"),\n",
    "        \"status_type_id\": item.get(\"StatusTypeID\"),\n",
    "        \"data_provider_id\": item.get(\"DataProviderID\"),\n",
    "        \"date_created\": item.get(\"DateCreated\"),\n",
    "        \"date_updated\": item.get(\"DateLastStatusUpdate\")\n",
    "    })\n",
    "\n",
    "    op = item.get(\"OperatorInfo\")\n",
    "    if op:\n",
    "        operators[op[\"ID\"]] = {\n",
    "            \"operator_id\": op[\"ID\"],\n",
    "            \"title\": op.get(\"Title\"),\n",
    "            \"website\": op.get(\"WebsiteURL\"),\n",
    "        }\n",
    "\n",
    "    if country:\n",
    "        countries[country[\"ID\"]] = {\n",
    "            \"country_id\": country[\"ID\"],\n",
    "            \"title\": country.get(\"Title\"),\n",
    "            \"iso_code\": country.get(\"ISOCode\"),\n",
    "            \"continent_code\": country.get(\"ContinentCode\")\n",
    "        }\n",
    "\n",
    "    for conn in item.get(\"Connections\", []):\n",
    "        connections.append({\n",
    "            \"connection_id\": conn.get(\"ID\"),\n",
    "            \"station_id\": station_id,\n",
    "            \"connection_type_id\": conn.get(\"ConnectionTypeID\"),\n",
    "            \"level_id\": conn.get(\"LevelID\"),\n",
    "            \"current_type_id\": conn.get(\"CurrentTypeID\"),\n",
    "            \"voltage\": conn.get(\"Voltage\"),\n",
    "            \"amps\": conn.get(\"Amps\"),\n",
    "            \"power_kw\": conn.get(\"PowerKW\"),\n",
    "            \"quantity\": conn.get(\"Quantity\"),\n",
    "        })\n",
    "\n",
    "        ct = conn.get(\"ConnectionType\")\n",
    "        if ct:\n",
    "            connection_types[ct[\"ID\"]] = {\n",
    "                \"connection_type_id\": ct[\"ID\"],\n",
    "                \"title\": ct.get(\"Title\"),\n",
    "                \"formal_name\": ct.get(\"FormalName\"),\n",
    "                \"is_obsolete\": ct.get(\"IsObsolete\"),\n",
    "                \"is_discontinued\": ct.get(\"IsDiscontinued\")\n",
    "            }\n",
    "\n",
    "        curr = conn.get(\"CurrentType\")\n",
    "        if curr:\n",
    "            current_types[curr[\"ID\"]] = {\n",
    "                \"current_type_id\": curr[\"ID\"],\n",
    "                \"title\": curr.get(\"Title\"),\n",
    "                \"description\": curr.get(\"Description\")\n",
    "            }\n",
    "\n",
    "\n",
    "df_stations = pd.DataFrame(stations)\n",
    "df_stations = df_stations.astype({\n",
    "    \"station_id\": \"Int64\",\n",
    "    \"title\": \"string\",\n",
    "    \"city\": \"string\",\n",
    "    \"postcode\": \"string\",   # safer than float, to keep leading 0s\n",
    "    \"country_id\": \"Int64\",\n",
    "    \"latitude\": \"float64\",\n",
    "    \"longitude\": \"float64\",\n",
    "    \"operator_id\": \"Int64\",\n",
    "    \"usage_type_id\": \"Int64\",\n",
    "    \"status_type_id\": \"Int64\",\n",
    "    \"data_provider_id\": \"Int64\",\n",
    "    \"date_created\": \"string\",  # parse as datetime separately\n",
    "    \"date_updated\": \"string\"\n",
    "})\n",
    "df_stations.to_csv(\"../data/charging_stations.csv\", index=False)\n",
    "\n",
    "df_connections = pd.DataFrame(connections)\n",
    "\n",
    "# Round float values before casting to Int64\n",
    "for col in [\n",
    "    \"connection_id\", \"station_id\", \"connection_type_id\",\n",
    "    \"level_id\", \"current_type_id\", \"voltage\", \"amps\",\n",
    "    \"power_kw\", \"quantity\"\n",
    "]:\n",
    "    if col in df_connections.columns:\n",
    "        df_connections[col] = df_connections[col].apply(\n",
    "            lambda x: round(x) if pd.notnull(x) else pd.NA\n",
    "        )\n",
    "\n",
    "df_connections = df_connections.astype({\n",
    "    \"connection_id\": \"Int64\",\n",
    "    \"station_id\": \"Int64\",\n",
    "    \"connection_type_id\": \"Int64\",\n",
    "    \"level_id\": \"Int64\",\n",
    "    \"current_type_id\": \"Int64\",\n",
    "    \"voltage\": \"Int64\",\n",
    "    \"amps\": \"Int64\",\n",
    "    \"power_kw\": \"Int64\",\n",
    "    \"quantity\": \"Int64\"\n",
    "})\n",
    "df_connections.to_csv(\"../data/connections.csv\", index=False)\n",
    "\n",
    "df_operators = pd.DataFrame(operators.values())\n",
    "df_operators = df_operators.astype({\n",
    "    \"operator_id\": \"Int64\",\n",
    "    \"title\": \"string\",\n",
    "    \"website\": \"string\"\n",
    "})\n",
    "df_operators.to_csv(\"../data/operators.csv\", index=False)\n",
    "\n",
    "df_countries = pd.DataFrame(countries.values())\n",
    "df_countries = df_countries.astype({\n",
    "    \"country_id\": \"Int64\",\n",
    "    \"title\": \"string\",\n",
    "    \"iso_code\": \"string\",\n",
    "    \"continent_code\": \"string\"\n",
    "})\n",
    "df_countries.to_csv(\"../data/countries.csv\", index=False)\n",
    "\n",
    "df_current_types = pd.DataFrame(current_types.values())\n",
    "df_current_types = df_current_types.astype({\n",
    "    \"current_type_id\": \"Int64\",\n",
    "    \"title\": \"string\",\n",
    "    \"description\": \"string\"\n",
    "})\n",
    "df_current_types.to_csv(\"../data/current_types.csv\", index=False)\n",
    "\n",
    "df_connection_types = pd.DataFrame(connection_types.values()).astype({\n",
    "    \"connection_type_id\": \"Int64\",\n",
    "    \"title\": \"string\",\n",
    "    \"formal_name\": \"string\",\n",
    "    \"is_obsolete\": \"boolean\",\n",
    "    \"is_discontinued\": \"boolean\"\n",
    "})\n",
    "df_connection_types.to_csv(\"../data/connection_types.csv\", index=False)\n",
    "\n",
    "\n",
    "print(f\"Exported {len(stations)} stations\")\n",
    "print(f\"Exported {len(connections)} connections\")\n",
    "print(f\"Exported {len(operators)} operators\")\n",
    "print(f\"Exported {len(countries)} countries\")\n",
    "print(f\"Exported {len(current_types)} current types\")\n",
    "print(f\"Exported {len(connection_types)} connection types\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
